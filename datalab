curl -X POST  -H 'Content-Type: application/json' -d '{"schemas":[{"name":"test1", "schema":{"type":"record","name":"row","fields":[{"name":"testvalue","type":{"type":"string","arg.properties":{"options":["ÅÄÖ!#$€%&"]}}}]}}]}' -k https://0.0.0.0:5000/validateSchema --user niklas.molin


fail incorrect union:

curl -X POST  -H 'Content-Type: application/json' -d '{"schemas":[{"name":"test1", "schema":{"type":"record","name":"row","fields":[{"name":"testvalue","type":{"type":["string","double"],"arg.properties":{"options":["ÅÄÖ!#$€%&"]}}}]}}]}' -k https://0.0.0.0:5000/validateSchema --user niklas.molin



## CONFIGURE THE CLI 

don't know how necessary all of the paras are but we used the profile later on this is
ecs-cli configure --cluster datalab --default-launch-type FARGATE --config-name datalab --region eu-west-1

ecs-cli configure profile --access-key $AWS_ACCESS_KEY_ID --secret-key $AWS_SECRET_ACCESS_KEY --profile-name lab_profile

## CREATE A CLUSTER 

Based on the config, using our VPC and looking for the subnet from our eks cluster. 

ecs-cli up --cluster-config  datalab --ecs-profile lab_profile --tags SystemID=lakehouse-alps,Team=data-dpf --vpc vpc-22bdad45 --subnets subnet-0a571351 --force

ecs-cli down --cluster-config  datalab --ecs-profile lab_profile --tags SystemID=lakehouse-alps,Team=data-dpf --vpc vpc-22bdad45 --subnets subnet-0a571351,subnet-eb414da2 --force

## Uploading the docker image. 

### create a new repo 

aws ecr create-repository --repository-name data-dpf/datalab --tags Key=Team,Value=data-dpf 

login 
in the instructions:
aws ecr get-login-password --region eu-west-1 | docker login --username AWS --password-stdin 801273904165.dkr.ecr.eu-west-1.amazonaws.com
doesn't work 
this kind of does:

login=$(aws ecr get-login --region eu-west-1)
${login/" -e none"/" "}

### Build and push
the image isn't constructed as it should and take forever to build 

docker tag alpscore-app:latest 801273904165.dkr.ecr.eu-west-1.amazonaws.com/data-dpf/alpscore:alpscore-app

docker push 801273904165.dkr.ecr.eu-west-1.amazonaws.com/data-dpf/alpscore:alpscore-app

### DEPLOY

ECS in now nativly suppoted in docker compose, but a lot of stuff doesn't seem to be supported. For starters could figure out how to set tags, so didn't dare to create something.

ecs-cli compose up --cluster-config  datalab --ecs-profile lab_profile --tags SystemID=lakehouse-alps,Team=data-dpf 

####
Run a task manually. If created with the above docker-compose statement we always get a new task id. And we don't need to override the taskdefinition here.

aws ecs run-task --cluster datalab --launch-type FARGATE --task-definition alps:1 --propagate-tags "TASK_DEFINITION" --tags "key=Team,value=data-dpf" --network-configuration "awsvpcConfiguration={subnets=[subnet-0a571351],securityGroups=[sg-069b03afefb4aa29c],assignPublicIp=DISABLED}"

## Authentication 
Had some fancy okta login but switch to ldap.
https://developer.okta.com/blog/2018/07/10/build-a-basic-crud-app-with-node-and-react


## DEV Build

docker run  -p 5000:5000 -e AWS_SESSION_TOKEN=$AWS_SESSION_TOKEN -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY alpscore-app:latest  -XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap -XX:MaxRAMFraction=2 -XshowSettings:vm -version

docker --context default compose up -f docker-compose-local.yml

test run
make docker-build MODULE=app 
docker run -p 5000:5000 alpscore:alpscore-app



curl -X POST  -H 'Content-Type: application/json' -d '{"schemas":[{"name":"test1", "schema":{"type":"record","name":"row","fields":[{"name":"testvalue","type":{"type":["string","double"],"arg.properties":{"options":["ÅÄÖ!#$€%&"]}}}]}}]}' -k https://10.254.102.217:5000/validateSchema --user niklas.molin

curl -X GET  -H 'Content-Type: application/json' -k https://0.0.0.0:5000/task_test --user niklas.molin

[ req ]
default_bits       = 4096
distinguished_name = req_distinguished_name
req_extensions     = req_ext
prompt             = no

[ req_distinguished_name ]
commonName                  = 192.168.1.10

[ req_ext ]
subjectAltName = IP:192.168.1.10

openssl genrsa -out key1.pem
openssl req -new -key key1.pem -out csr1.pem -config ../ssl.conf
openssl x509 -req -days 9999 -in csr1.pem -signkey key1.pem -out datalab.pem -extensions req_ext -extfile ../ssl.conf
rm csr1.pem

openssl genrsa -out datalab.key 2048
openssl req -new -key datalab.key -out datalab.csr  -config ../ssl.conf
openssl x509 -req -days 365 -in datalab.csr -signkey datalab.key -out datalab.crt -extfile ../v3.ext


docker run  -v $PWD/app:/home/klarna/alpscore/app \
	-v $PWD/keys:/home/klarna/alpscore/keys \
	-v $PWD/web/build:/home/klarna/alpscore/web \
 	-v $PWD/alpscore:/home/klarna/alpscore/alpscore -p 5000:5000 \
	-e AWS_SESSION_TOKEN=$AWS_SESSION_TOKEN \
	-e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID \
	-e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY \
	alpscore-app:latest  -XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap -XX:MaxRAMFraction=2 -XshowSettings:vm -version

docker build -f docker/Dockerfile-app -t alpscore-app:latest .
docker tag alpscore:alpscore-app l-docker-data-processing-frameworks-staging.artifactory.klarna.net/data-processing-frameworks/alpscore/alpscore-app:latest

docker push l-docker-data-processing-frameworks-staging.artifactory.klarna.net/data-processing-frameworks/alpscore/alpscore-app:latest

docker login l-docker-data-processing-frameworks-staging.artifactory.klarna.net
docker pull l-docker-data-processing-frameworks-staging.artifactory.klarna.net/data-processing-frameworks/alpscore/alpscore-app:latest

AWS MENU

docker run -p 5000:5000 \
	-e AWS_SESSION_TOKEN=$AWS_SESSION_TOKEN \
	-e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID \
	-e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY \
	l-docker-data-processing-frameworks-staging.artifactory.klarna.net/data-processing-frameworks/alpscore/alpscore-app:latest


l-docker-data-processing-frameworks-staging.artifactory.klarna.net/data-processing-frameworks/alpscore/alpscore-app:latest
PULL_REGISTRY=docker.artifactory.klarna.net/data-processing-frameworks

docker run  -v $PWD/app:/home/klarna/alpscore/app -v $PWD/keys:/home/klarna/alpscore/keys -v $PWD/web/build:/home/klarna/alpscore/web  -v $PWD/alpscore:/home/klarna/alpscore/alpscore -p 5000:5000 -e AWS_SESSION_TOKEN=$AWS_SESSION_TOKEN -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY alpscore-app:latest  -XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap -XX:MaxRAMFraction=2 -XshowSettings:vm -version

{"type":"record","name":"row","fields":[{"name":"testvalue","type":{"type":"string","arg.properties":{"options":["ÅÄÖ!#$€%&"]}}}]}

docker push 801273904165.dkr.ecr.eu-west-1.amazonaws.com/data-dpf/alpscore:alpscore-app

docker run -p 5000:5000 \
	-e AWS_SESSION_TOKEN=$AWS_SESSION_TOKEN \
	-e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID \
	-e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY \
	--name alps \
 	-e POSTGRES_PASSWORD=alps \
 	-e POSTGRES_USER=klarna \
 	-e POSTGRES_DB=alps \
	-e PGDATA=/var/lib/postgresql/data/pgdata \
    -v $PWD/pg/scripts:/docker-entrypoint-initdb.d \
	-v $PWD/app:/home/klarna/alpscore/app \
	-v $PWD/keys:/home/klarna/alpscore/keys \
	-v $PWD/web/build:/home/klarna/alpscore/web \
 	-v $PWD/alpscore:/home/klarna/alpscore/alpscore \
	alpscore-app:latest




alpscore --local_dev true --conf spark.executor.memoryOverhead 3000 --conf spark.driver.memory 5g --conf spark.sql.parquet.enableVectorizedReader false --extra_jars "jars/spark-avro_2.11-2.4.3.jar" main_transform --payload_format 'avro' --input_path 's3://eu-production-klarna-data-eu/silos/streaming/kafka/eu-production/eu-production_freshdesk_on-ticket-update-events_v1/kcv1/eu-production.freshdesk.on-ticket-update-events.v1/' --input_db 'streaming_sources_eu_data_admin' --input_table 'eu_production_freshdesk_on_ticket_update_events_v1_v1' --output_path 's3://eu-production-klarna-data-transformed-eu/alps/eu_production_freshdesk_on_ticket_update_events_v1_v1/' --schema_path 's3://eu-production-klarna-data-eu/confluent/' --schema_file_format 'parquet' --output_db 'transformed_alps_production_eu' --glue_role 'alps_glue_role' --chunk_size 2 --data_version '1_0_0' --reader 'glue' --trace False --overwrite False --data_filter "ts<'2020120309' and ts>='2020120307'"

alpscore --local_dev true --conf spark.sql.parquet.enableVectorizedReader false --extra_jars "jars/spark-avro_2.11-2.4.3.jar" main_transform --payload_format 'avro' --input_path 's3://eu-production-klarna-data-eu/silos/streaming/kafka/eu-production/eu-production_freshdesk_on-ticket-update-events_v1/kcv1/eu-production.freshdesk.on-ticket-update-events.v1/' --input_db 'streaming_sources_eu_data_admin' --input_table 'eu_production_freshdesk_on_ticket_update_events_v1_v1' --output_path 's3://eu-production-klarna-data-transformed-eu/alps/eu_production_freshdesk_on_ticket_update_events_v1_v1/' --schema_path 's3://eu-production-klarna-data-eu/confluent/' --schema_file_format 'parquet' --output_db 'transformed_alps_production_eu' --glue_role 'alps_glue_role' --chunk_size 2 --data_version '1_0_0' --reader 'glue' --trace False --overwrite False
repartitioned.dataframes[0].dataframe.cache().count()

alpscore --local_dev true --conf spark.sql.parquet.enableVectorizedReader false --extra_jars "jars/spark-avro_2.11-2.4.3.jar" main_transform --payload_format 'avro' --input_path 's3://eu-production-klarna-data-eu/silos/streaming/kafka/eu-production/eu-production_freshdesk_on-ticket-update-events_v1/kcv1/eu-production.freshdesk.on-ticket-update-events.v1/' --input_db 'streaming_sources_eu_data_admin' --input_table 'eu_production_freshdesk_on_ticket_update_events_v1_v1' --output_path 's3://eu-production-klarna-data-transformed-eu/alps/eu_production_freshdesk_on_ticket_update_events_v1_v1/' --schema_path 's3://eu-production-klarna-data-eu/confluent/' --schema_file_format 'parquet' --output_db 'transformed_alps_production_eu' --glue_role 'alps_glue_role' --chunk_size 2 --data_version '1_0_0' --reader 'glue' --trace False --overwrite False

alpscore --conf spark.python.worker.reuse false --conf spark.executor.memoryOverhead 4000 --conf spark.executor.memory 5g --conf spark.eventLog.enabled true --conf spark.eventLog.dir log --local_dev true --conf spark.sql.parquet.enableVectorizedReader false main_transform --payload_format 'json' --input_path 's3://eu-production-klarna-data-eu/silos/streaming/kafka/eu-production/eu_production_plsi_pams_pay_in_parts_analytics_v1/kcv1/eu-production.pams.pay-in-parts-analytics.v1/' --input_db 'streaming_sources_eu_data_admin' --input_table 'eu_production_plsi_pams_pay_in_parts_analytics_v1' --output_path 's3://eu-production-klarna-data-transformed-eu/alps/eu_production_plsi_pams_pay_in_parts_analytics_v1/' --schema_path 's3://eu-production-klarna-data-eu/confluent/' --schema_file_format 'parquet' --output_db 'transformed_alps_production_eu' --glue_role 'alps_glue_role' --chunk_size 2 --data_version '1_0_0' --reader 'glue' --trace False --overwrite False --data_filter "ts<'2020120410' and ts>='2020120408'"

aws s3 sync log s3://eu-production-klarna-data-transformed-eu/alps_logs/di_2658/

make start-sparkUI S3_LOG_PREFIX=s3a://eu-production-klarna-data-transformed-eu/alps_logs/di_2658/

aws s3 sync log s3://eu-production-klarna-data-transformed-eu/alps_logs/di_26582/

alpscore --conf spark.python.worker.reuse false --conf spark.executor.memoryOverhead 4000 --conf spark.executor.memory 5g --conf spark.eventLog.enabled true --conf spark.eventLog.dir log --local_dev true --conf spark.sql.parquet.enableVectorizedReader false test-transform-job --payload_format 'json' --input_path 's3://eu-production-klarna-data-eu/silos/streaming/kafka/eu-production/eu_production_plsi_pams_pay_in_parts_analytics_v1/kcv1/eu-production.pams.pay-in-parts-analytics.v1/' --input_db 'streaming_sources_eu' --input_table 'eu_production_plsi_pams_pay_in_parts_analytics_v1' --output_path 's3://eu-production-klarna-data-transformed-eu/alps/eu_production_plsi_pams_pay_in_parts_analytics_v1/' --schema_path 's3://eu-production-klarna-data-eu/confluent/' --schema_file_format 'parquet' --output_db 'transformed_alps_production_eu' --glue_role 'alps_glue_role' --chunk_size 2 --data_version '1_0_0' --reader 'glue' --trace False --overwrite False --data_filter "ts<'2020121010' and ts>='2020120803'"

eval $(minikube docker-env)
kubectl run alpscore-app --image=alpscore-app -it --restart=Never ----image-pull-policy='Never'  -- /bin/sh	

kubectl run alpscore-app --image=alpscore-app -it --restart=Never -- /bin/sh